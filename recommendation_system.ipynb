{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requiremnets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Base Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from evaluation import ModelEvaluator\n",
    "from models import (\n",
    "    PopularityRecommendationModel,\n",
    "    PopularityYearRecommendationModel,\n",
    "    ContentBasedRecommendationModel,\n",
    "    CollaborativeRecommendationModel,\n",
    "    HybridRecommendationModel\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.dataset_utils import (\n",
    "    preprocess_books,\n",
    "    preprocess_ratings,\n",
    "    drop_irrelevant_books\n",
    ")\n",
    "from utils.df_utils import (\n",
    "    load_books_dataset,\n",
    "    load_ratings_dataset,\n",
    "    get_users_subset,\n",
    "    intersect_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing Books Steps.\n",
    "1. drop nan values.\n",
    "2. removing books that has year = 0.\n",
    "3. removing books that has an Unknown Publisher.\n",
    "4. removing books that has an Unknown Author.\n",
    "5. drop irrelevant publishers: drop books with publishers that doesn't have a lot of occurrences.\n",
    "6. drop irrelevant authors: drop books with authors that doesn't have a lot of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "books, dropped_books = preprocess_books(\n",
    "    load_books_dataset(\"dataset/Books.csv\"),\n",
    "    # this one will reduce the number of district authors/publishers\n",
    "    # values and there for will be having less sparsity when working with\n",
    "    # their vectors.\n",
    "    drop_irrelevant_publishers=100,\n",
    "    drop_irrelevant_authors=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading and Preprocessing Ratings.\n",
    "## Preprocessing Ratings Steps.\n",
    "1. drop nan values.\n",
    "2. drop users that has a total ratings sum of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings = load_ratings_dataset(\"dataset/Ratings.csv\", drop_books=dropped_books)\n",
    "\n",
    "full_train_data, full_test_data = train_test_split(ratings, test_size=0.15)\n",
    "\n",
    "full_train_data = preprocess_ratings(full_train_data)\n",
    "full_test_data = preprocess_ratings(full_test_data)\n",
    "\n",
    "popularity_data = get_users_subset(full_train_data, full_test_data, 3000)\n",
    "sun_train_popularity_data = popularity_data[\"train_data\"]\n",
    "sub_test_popularity_data = popularity_data[\"test_data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluator\n",
    "the popularity prediction is so fast I want extra marks for that :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "popularity_evaluator = ModelEvaluator(\n",
    "    training_data=sun_train_popularity_data,\n",
    "    testing_data=sub_test_popularity_data,\n",
    "    favourite_threshold=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity Recommendation Model Loaded...\n",
      "Running Evaluation for Popularity Recommendation Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:16<00:00, 177.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 3000 users\n",
      "Finished Popularity Recommendation Model Evaluation...\n",
      "{'model_name': 'Popularity Recommendation Model', 'recall@5': 0.6, 'recall@10': 1.0, 'precision@5': 0.0002, 'precision@10': 0.00016666666666666666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "popularity_rec_model = PopularityRecommendationModel(\n",
    "    books, sun_train_popularity_data, threshold=5\n",
    ")\n",
    "print(f\"{popularity_rec_model.MODEL_NAME} Loaded...\")\n",
    "\n",
    "pop_global_metrics, _ = popularity_evaluator.evaluate_model(popularity_rec_model)\n",
    "\n",
    "print(pop_global_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2- Popularity Year Based Model\n",
    "This model is combining the popularity IMDB formula and then adding a year factor using the following equation:\n",
    "popularity = (v/(v+m) * r) + (m/(m+v) * c)\n",
    "popularity_year = popularity * (book_year - oldest_book_year)\n",
    "where:\n",
    "v is the number of ratings for the book.\n",
    "m is the minimum rating required to be listed in the chart.\n",
    "r is the average rating of the book.\n",
    "c is the mean ratings across the whole books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity Year Based Recommendation Model Loaded...\n",
      "Running Evaluation for Popularity Year Based Recommendation Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:17<00:00, 172.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 3000 users\n",
      "Finished Popularity Year Based Recommendation Model Evaluation...\n",
      "{'model_name': 'Popularity Year Based Recommendation Model', 'recall@5': 0.5714285714285714, 'recall@10': 1.0, 'precision@5': 0.0002666666666666667, 'precision@10': 0.00023333333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "popularity_year_rec_model = PopularityYearRecommendationModel(\n",
    "    books, sun_train_popularity_data, threshold=5\n",
    ")\n",
    "print(f\"{popularity_year_rec_model.MODEL_NAME} Loaded...\")\n",
    "\n",
    "pop_year_global_metrics, _ = popularity_evaluator.evaluate_model(popularity_year_rec_model)\n",
    "\n",
    "print(pop_year_global_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Content Based Recommendation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluator\n",
    "we will need to use a smaller test set because the model is slower, didn't have time to optimize this one :(."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "content_data = get_users_subset(full_train_data, full_test_data, 1000)\n",
    "sub_train_content_data = content_data[\"train_data\"]\n",
    "sub_test_content_data = content_data[\"test_data\"]\n",
    "\n",
    "content_evaluator = ModelEvaluator(\n",
    "    training_data=sub_train_content_data,\n",
    "    testing_data=sub_test_content_data,\n",
    "    favourite_threshold=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3- Content Based Recommendation Model (Publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allonios/PycharmProjects/books_recommendation_system/recommendation_system/models.py:86: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  self.books_features = self.books_df[self.features_names]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluation for Content Based Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:15<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1000 users\n",
      "Finished Content Based Model Evaluation...\n",
      "{'model_name': 'Content Based Model', 'recall@5': 0.7142857142857143, 'recall@10': 1.0, 'precision@5': 0.001, 'precision@10': 0.0007030936118923262}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pub_content_rec_model = ContentBasedRecommendationModel(\n",
    "    column_name=\"publisher\", books_df=books, ratings_df=sub_train_content_data\n",
    ")\n",
    "\n",
    "pub_content_global_metrics, _ = content_evaluator.evaluate_model(pub_content_rec_model)\n",
    "\n",
    "print(pub_content_global_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4- Content Based Recommendation Model (Author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluation for Content Based Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:55<00:00,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1000 users\n",
      "Finished Content Based Model Evaluation...\n",
      "{'model_name': 'Content Based Model', 'recall@5': 0.125, 'recall@10': 1.0, 'precision@5': 0.00020008003201280514, 'precision@10': 0.0008081624406505708}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "auth_content_rec_model = ContentBasedRecommendationModel(\n",
    "    column_name=\"author\", books_df=books, ratings_df=sub_train_content_data\n",
    ")\n",
    "\n",
    "auth_content_global_metrics, _ = content_evaluator.evaluate_model(auth_content_rec_model)\n",
    "\n",
    "print(auth_content_global_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5- Collaborative Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluation for Collaborative Filtering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:15<00:00, 192.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 3000 users\n",
      "Finished Collaborative Filtering Evaluation...\n",
      "{'model_name': 'Collaborative Filtering', 'recall@5': 0.7333333333333333, 'recall@10': 1.0, 'precision@5': 0.04326666666666667, 'precision@10': 0.0295}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# similar to reducing the number of irrelevant authors/publishers\n",
    "# we are going to reduce the number of books, we will be loading around 460 books.\n",
    "collab_ratings = drop_irrelevant_books(ratings, threshold=200)\n",
    "\n",
    "full_collab_train_data, full_collab_test_data = train_test_split(\n",
    "    collab_ratings, test_size=0.15\n",
    ")\n",
    "\n",
    "full_collab_train_data = preprocess_ratings(full_collab_train_data)\n",
    "full_collab_test_data = preprocess_ratings(full_collab_test_data)\n",
    "\n",
    "collab_data = get_users_subset(\n",
    "    full_collab_train_data, full_collab_test_data, 3000\n",
    ")\n",
    "\n",
    "collab_evaluator = ModelEvaluator(\n",
    "    training_data=collab_data[\"train_data\"],\n",
    "    testing_data=collab_data[\"test_data\"],\n",
    "    favourite_threshold=1,\n",
    ")\n",
    "\n",
    "collaborative_rec_model = CollaborativeRecommendationModel(\n",
    "    ratings_df=collab_ratings\n",
    ")\n",
    "\n",
    "collab_global_metrics, _ = collab_evaluator.evaluate_model(\n",
    "    collaborative_rec_model\n",
    ")\n",
    "\n",
    "print(collab_global_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6- Hybrid Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluation for Hybrid Recommendation Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:41<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 343 users\n",
      "Finished Hybrid Recommendation Model Evaluation...\n",
      "{'model_name': 'Hybrid Recommendation Model', 'recall@5': 0.0, 'recall@10': 1.0, 'precision@5': 0.0, 'precision@10': 0.016622922134733157}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hybrid_train_data, _ = intersect_df(\n",
    "    content_data[\"train_data\"], collab_data[\"train_data\"], \"book_id\"\n",
    ")\n",
    "\n",
    "hybrid_test_data, _ = intersect_df(\n",
    "    content_data[\"test_data\"], collab_data[\"test_data\"], \"book_id\"\n",
    ")\n",
    "\n",
    "hybrid_evaluator = ModelEvaluator(\n",
    "    training_data=hybrid_train_data,\n",
    "    testing_data=hybrid_test_data,\n",
    "    favourite_threshold=1,\n",
    ")\n",
    "\n",
    "hybrid_rec_model = HybridRecommendationModel(\n",
    "    content_column_name=\"author\",\n",
    "    content_books_df=books,\n",
    "    content_ratings_df=content_data[\"train_data\"],\n",
    "    collab_ratings_df=collab_ratings\n",
    ")\n",
    "\n",
    "hybrid_global_metrics, _ = hybrid_evaluator.evaluate_model(\n",
    "    hybrid_rec_model\n",
    ")\n",
    "\n",
    "print(hybrid_global_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}